#!/usr/bin/env Rscript
# DOC
# Generate Hubverse-formatted target data for the FluSight Forecast hub.
#
# USAGE
#     Rscript "get_target_data_hubverse.R" as_of include_after
#
# ARGUMENTS
#     as_of: Optional "YYYY-MM-DD" string.
#                    If provided, read archived target data instead of the latest version.
#     include_after: Optional "YYYY-MM-DD" string.
#                    Exlucde target data dated on or earlier than this date. Defaults to "2024-11-01".
#                    Note: the modeling tasks defined in tasks.json were updated for the 2024-2025 flu
#                    season, so don't run this script with an include_after date before 2024-11-01.
#
# EXAMPLE
#     Generate Hubverse target data based on the latest available FluSight target-hospital-admissions.csv
#     `Rscript "get_target_data_hubverse.R"`
#
#     Generate Hubverse target data based on the 2025-01-11 archived version of FluSight target-hospital-admissions.csv
#     Rscript "get_target_data_hubverse.R" 2025-01-11
#
# DOC
here::i_am("target-data/get_target_data_hubverse.R")
library(cli)
suppressPackageStartupMessages(library(dplyr))
library(readr)
library(tidyr)

options(readr.show_col_types = FALSE)

#' @description
#' `get_location_data` returns supplemental information about locations used in
#' the FluSight Forecast hub.
#'
#' @returns A dataframe with four columns: abbreviation (two-letter state code),
#' location (FIPS code), location_name (state name), and population.
get_location_data <- function() {
  location_file <-
    read_csv(file = "https://raw.githubusercontent.com/cdcepi/FluSight-forecast-hub/main/auxiliary-data/locations.csv") # nolint: line_length_linter.
  # first 4 columns of locations.csv are abbreviation, location, location_name, population
  location_file %>% dplyr::select(1:4)
}

#' @description
#' `get_base_target_data` returns weekly target data generated by the FluSight
#' FluSight Forecast hub.
#'
#' @param as_of Optional "YYYY-MM-DD" string. If provided, read archived target data instead of the latest version.
#' @returns A dataframe
get_base_target_data <- function(include_after, as_of = NULL) {
  # if as_of is not provided, read the latest target data
  if (is.null(as_of) || is.na(as_of)) {
    get_latest <- TRUE
  } else {
    get_latest <- FALSE
  }

  if (get_latest) {
    file_name <- file.path(here::here(), "target-data/target-hospital-admissions.csv")
  } else {
    file_name <- file.path(
      here::here(),
      paste0("auxiliary-data/target-data-archive/target-hospital-admissions_", as_of, ".csv"))
  }

  cli::cli_inform(paste0("Reading target data from ", file_name, "..."))

  base_target_data <- readr::read_csv(file = file_name)
  latest_date <- max(base_target_data$date, na.rm = TRUE)

  if (!get_latest && as.Date(latest_date) != as.Date(as_of)) {
    cli::cli_alert_danger(
      paste0("Latest date in the target data (", latest_date, ") does not match the 'as_of' date (", as_of, ").")
    )
    stop()
  }

  base_target_data <- cbind(
    base_target_data,
    data.frame(as_of = as.Date(latest_date))
  )

  base_target_data
}

#' @description
#' `create_time_series_target_data` creates Hubverse-formatted time series
#' target data for the "wk inc flu hosp" target.
#' "wk inc flu hosp" is the only target eligible for inclusion in the time series
#' data because it is both continuous and step-ahead.
#'
#' @param weekly_data Dataframe with weekly target data generated by the hub.
#' @param location_date Dataframe with information about each state.
#' @returns A dataframe
create_time_series_target_data <- function(weekly_data, location_data) {

  weekly_data <- weekly_data %>%
    dplyr::select(-location) %>%
    dplyr::inner_join(location_data,
                        by = c("location_name"))
  time_series_wk_inc <- cbind(
    data.frame(target = "wk inc flu hosp"),
    weekly_data[c("date", "location", "value", "weekly_rate", "as_of")]
  )
  colnames(time_series_wk_inc) <- c("target", "target_end_date", "location", "observation", "weekly_rate", "as_of")

  time_series_wk_inc
}

#' @description
#' `create_oracle_output_target_data` creates Hubverse-formatted oracle output
#' target data.
#'
#' @param time_series_target Dataframe with the time series target data.
#' @returns A dataframe
create_oracle_output_target_data <- function(time_series_target) {
  oracle_output_wk_inc <- create_oracle_output_wk_inc(time_series_target)
  oracle_output_rate_change <- calc_oracle_output_rate_change(time_series_target)

  oracle_output <- dplyr::bind_rows(oracle_output_wk_inc, oracle_output_rate_change)
  oracle_output <- oracle_output[
    c("target", "location", "horizon", "target_end_date", "output_type_id", "oracle_value", "as_of")]

  oracle_output
}

#' @description
#' `create_oracle_output_wk_inc` creates Hubverse-formatted oracle output
#' target data for the "wk inc flu hosp" target.
#'
#' @param time_series_target Dataframe of Hubverse-formatted time series target data.
#' @returns A dataframe
create_oracle_output_wk_inc <- function(time_series_target) {
  oracle_output_wk_inc <- cbind(
    data.frame(target = "wk inc flu hosp"),
    time_series_target[c("target_end_date", "location", "observation", "as_of")]
  )
  colnames(oracle_output_wk_inc) <- c("target", "target_end_date", "location", "oracle_value", "as_of")
  oracle_output_wk_inc <- oracle_output_wk_inc %>%
    dplyr::cross_join(
      # add a row for each horizon defined in the modeling task
      # (except horizon -1, which is not used for scoring/viz)
      data.frame(horizon = 0:3)
    )
}

#' @description
#' `create_oracle_output_rate_change` creates Hubverse-formatted oracle output
#' target data for the "wk flu hosp rate change" target. It creates a "category"
#' column that contains the observed category for each location, date,
#' and horizon.
#'
#' Categories are "large_decrease", "decrease", "stable", "increase",
#' and "large_increase".
#'
#' @param time_series_target Dataframe of Hubverse-formatted time series target data.
#' @returns A dataframe
calc_oracle_output_rate_change <- function(time_series_target) {
  obs_categories <- time_series_target %>%
    dplyr::group_by(.data$location) %>%
    dplyr::arrange(.data$target_end_date) %>%
    dplyr::mutate(
      rate_diff0 = .data$weekly_rate - lag(.data$weekly_rate, 1),
      rate_diff1 = .data$weekly_rate - lag(.data$weekly_rate, 2),
      rate_diff2 = .data$weekly_rate - lag(.data$weekly_rate, 3),
      rate_diff3 = .data$weekly_rate - lag(.data$weekly_rate, 4),
      count_change0 = .data$observation - lag(.data$observation, 1),
      count_change1 = .data$observation - lag(.data$observation, 2),
      count_change2 = .data$observation - lag(.data$observation, 3),
      count_change3 = .data$observation - lag(.data$observation, 4)
    ) %>%
    dplyr::ungroup() %>%
    tidyr::pivot_longer(
      cols = c("rate_diff0", "rate_diff1", "rate_diff2", "rate_diff3"),
      names_to = "horizon",
      names_prefix = "rate_diff",
      values_to = "rate_diff",
      names_transform = list(horizon = as.integer)
    ) %>%
    dplyr::mutate(
      category = case_when(
        horizon == 0 & (abs(count_change0) < 10 | rate_diff < 0.3 & rate_diff > -0.3) ~ "stable",
        horizon == 0 & rate_diff > 1.7 ~ "large_increase",
        horizon == 0 & rate_diff < -1.7 ~ "large_decrease",
        horizon == 0 & rate_diff >= 0.3 ~ "increase",
        horizon == 0 & rate_diff <= -0.3 ~ "decrease",
        horizon == 1 & (abs(count_change1) < 10 | rate_diff < 0.5 & rate_diff > -0.5) ~ "stable",
        horizon == 1 & rate_diff > 3 ~ "large_increase",
        horizon == 1 & rate_diff < -3 ~ "large_decrease",
        horizon == 1 & rate_diff >= 0.5 ~ "increase",
        horizon == 1 & rate_diff <= -0.5 ~ "decrease",
        horizon == 2 & (abs(count_change2) < 10 | rate_diff < 0.7  & rate_diff > -0.7) ~ "stable",
        horizon == 2 & rate_diff > 4 ~ "large_increase",
        horizon == 2 & rate_diff < -4 ~ "large_decrease",
        horizon == 2 & rate_diff >= 0.7 ~ "increase",
        horizon == 2 & rate_diff <= -0.7 ~ "decrease",
        horizon == 3 & (abs(count_change3) < 10 | rate_diff < 1  & rate_diff > -1) ~ "stable",
        horizon == 3 & rate_diff > 5 ~ "large_increase",
        horizon == 3 & rate_diff < -5 ~ "large_decrease",
        horizon == 3 & rate_diff >= 1 ~ "increase",
        horizon == 3 & rate_diff <= -1 ~ "decrease"
      )
    ) %>%
    dplyr::select("target_end_date", "location", "horizon", "category", "as_of") %>%
    dplyr::filter(!is.na(.data$category))

  # Convert to the format for oracle output, which has an oracle_value of 1 for
  # the observed category and 0 for all other categories.
  oracle_output <- obs_categories |>
    dplyr::select("target_end_date", "location", "horizon", "as_of") |>
    dplyr::cross_join(
      data.frame(output_type_id = c("large_decrease", "decrease", "stable", "increase", "large_increase"))
    ) |>
    dplyr::left_join(
      obs_categories |> dplyr::mutate(oracle_value = 1),
      by = c("target_end_date", "location", "horizon", "output_type_id" = "category", "as_of")
    ) |>
    dplyr::mutate(
      target = "wk flu hosp rate change",
      oracle_value = ifelse(is.na(.data$oracle_value), 0, 1)
    )

    oracle_output
}

test_time_series_output <- function() {
  # create a vector to store test results
  ok <- (TRUE)
  ok
}

run_target_data_tests <- function() {
  # create a vector to store test results
  ok <- (TRUE)

  # expected category is "stable":
  # - for WY (FIPS code 56), the population is small but all changes in counts are
  #   magnitude 9 or less.
  # - for US, the changes in rate are *smaller* in magnitude than
  #   +/- 0.3 at horizon 0, +/- 0.5 at horizon 1, +/- 0.7 at horizon 2, and
  #   +/- 1 at horizon 3.
  location_data <- get_location_data()
  obs_dates <- seq.Date(from = as.Date("2024-11-02"), by = "week", length.out = 10)
  us_pop <- location_data |> dplyr::filter(location == "US") |> dplyr::pull("population")
  us_pop_100k <- function(c) {
    floor(c * us_pop / 100000)
  }
  test_data <- data.frame(
    location = c(rep("56", 10), rep("US", 10)),
    date = rep(obs_dates, 2),
    value = c(
      c(0, 0, 0, 0, 9, 0, 0, 0, 0, 0),
      c(0, us_pop_100k(0.2999), us_pop_100k(0.4998), us_pop_100k(0.6997),
        us_pop_100k(0.9996), us_pop_100k(0.6997), us_pop_100k(0.4998),
        us_pop_100k(0.2999), 0, 0)
    )
  ) |>
    dplyr::left_join(location_data, by = "location") |>
    dplyr::mutate(weekly_rate = .data$value / .data$population * 100000) |>
    dplyr::mutate(as_of = as.Date("2025-03-22"))

  test_ts_data <- create_time_series_target_data(test_data, location_data)
  test_oracle_output_rate_change <- calc_oracle_output_rate_change(test_ts_data)

  # all oracle values are 0 or 1
  ok <- append(ok, (all(unique(test_oracle_output_rate_change$oracle_value) %in% c(0, 1))))

  # for each date/location/horizon, oracle_value sums to 1
  ok <- append(ok,
    test_oracle_output_rate_change |>
      dplyr::group_by(.data$target_end_date, location, .data$horizon) |>
      dplyr::summarize(sum_oracle_value = sum(.data$oracle_value), .groups = "drop") |>
      dplyr::pull("sum_oracle_value") |>
      unique() |>
      all.equal(1)
  )

  # expected categories, all stable
  ok <- append(ok,
    test_oracle_output_rate_change |>
      dplyr::filter(.data$oracle_value > 0) |>
      dplyr::pull("output_type_id") |>
      unique() |>
      all.equal("stable")
  )

  # expected category is "increase" or "decrease"
  # test cases are all based on US to avoid edge cases that should be assigned to
  # "stable"
  # - changes in rate are in the following ranges:
  #   - horizon 0: (-1.7, -0.3] for decrease, [0.3, 1.7) for increase
  #   - horizon 1: (-3, -0.5] for decrease, [0.5, 3) for increase
  #   - horizon 2: (-4, -0.7] for decrease, [0.7, 4) for increase
  #   - horizon 3: (-5, -1] for decrease, [1, 5) for increase
  obs_dates <- seq.Date(from = as.Date("2024-11-02"), by = "week", length.out = 12)
  test_data <- data.frame(
    location = "US",
    date = obs_dates,
    value = c(
      0, us_pop_100k(1.1), us_pop_100k(2.2), us_pop_100k(3.3),
      us_pop_100k(4.4), us_pop_100k(4.4), us_pop_100k(4.4), us_pop_100k(4.4),
      us_pop_100k(3.3), us_pop_100k(2.2), us_pop_100k(1.1), 0
    )
  ) |>
    dplyr::left_join(location_data, by = "location") |>
    dplyr::mutate(weekly_rate = .data$value / .data$population * 100000) |>
    dplyr::mutate(as_of = as.Date("2025-03-22"))

  test_ts_data <- create_time_series_target_data(test_data, location_data)
  test_oracle_output_rate_change <- calc_oracle_output_rate_change(test_ts_data)

  # all oracle values are 0 or 1
  ok <- append(ok, all(unique(test_oracle_output_rate_change$oracle_value) %in% c(0, 1)))

  # for each date/location/horizon, oracle_value sums to 1
  ok <- append(ok,
    test_oracle_output_rate_change |>
      dplyr::group_by(.data$target_end_date, location, .data$horizon) |>
      dplyr::summarize(sum_oracle_value = sum(.data$oracle_value), .groups = "drop") |>
      dplyr::pull("sum_oracle_value") |>
      unique() |>
      all.equal(1)
  )

  # expected categories are:
  # - NA near beginning, where there is not enough history to calculate rate change
  # - "increase" for 4 weeks
  # - "stable" for a number of weeks depending on the lookback window used for rate change
  # - "decrease" for 4 weeks
  exp_categories <- data.frame(
    target_end_date = obs_dates,
    location = "US",
    horizon_0 = c(
                  rep(NA, 1), rep("increase", 4), rep("stable", 3), rep("decrease", 4)),
    horizon_1 = c(
                  rep(NA, 2), rep("increase", 4), rep("stable", 2), rep("decrease", 4)),
    horizon_2 = c(
                  rep(NA, 3), rep("increase", 4), rep("stable", 1), rep("decrease", 4)),
    horizon_3 = c(
                  rep(NA, 4), rep("increase", 4), rep("decrease", 4))
  ) |>
    tidyr::pivot_longer(
      cols = c("horizon_0", "horizon_1", "horizon_2", "horizon_3"),
      names_to = "horizon",
      values_to = "output_type_id",
      names_prefix = "horizon_"
    ) |>
    dplyr::mutate(horizon = as.integer(.data$horizon)) |>
    dplyr::filter(!is.na(.data$output_type_id))

  ok <- append(ok,
    test_oracle_output_rate_change |>
      dplyr::filter(
        .data$oracle_value > 0
      ) |>
      dplyr::select(-"oracle_value") |>
      dplyr::full_join(exp_categories, by = c("target_end_date", "location", "horizon")) |>
      dplyr::mutate(comparison = (.data$output_type_id.x == .data$output_type_id.y)) |>
      dplyr::pull("comparison") |>
      unique() |>
      all.equal(TRUE)
  )

  # expected category is "large_increase" or "large_decrease" (other categories incidentally tested)
  # test cases are all based on US to avoid edge cases that should be assigned to
  # "stable"
  # - changes in rate are in the following ranges:
  #   - horizon 0: (-infty, -1.7] for large_decrease, [1.7, infty) for large_increase
  #   - horizon 1: (-infty, -3] for large_decrease, [3, infty) for large_increase
  #   - horizon 2: (-infty, -4] for large_decrease, [4, infty) for large_increase
  #   - horizon 3: (-infty, z-5] for large_decrease, [5, infty) for large_increase
  obs_dates <- seq.Date(from = as.Date("2024-11-02"), by = "week", length.out = 12)
  test_data <- data.frame(
    location = "US",
    date = obs_dates,
    value = c(
      0, us_pop_100k(1.8), us_pop_100k(2 * 1.8), us_pop_100k(3 * 1.8),
      us_pop_100k(4 * 1.8), us_pop_100k(4 * 1.8), us_pop_100k(4 * 1.8), us_pop_100k(4 * 1.8),
      us_pop_100k(3 * 1.8), us_pop_100k(2 * 1.8), us_pop_100k(1 * 1.8), 0
    )
  ) |>
    dplyr::left_join(location_data, by = "location") |>
    dplyr::mutate(weekly_rate = .data$value / .data$population * 100000) |>
    dplyr::mutate(as_of = as.Date("2025-03-22"))

  test_ts_data <- create_time_series_target_data(test_data, location_data)
  test_oracle_output_rate_change <- calc_oracle_output_rate_change(test_ts_data)

  # all oracle values are 0 or 1
  ok <- append(ok, all(unique(test_oracle_output_rate_change$oracle_value) %in% c(0, 1)))

  # for each date/location/horizon, oracle_value sums to 1
  ok <- append(ok,
    test_oracle_output_rate_change |>
      dplyr::group_by(.data$target_end_date, location, .data$horizon) |>
      dplyr::summarize(sum_oracle_value = sum(.data$oracle_value), .groups = "drop") |>
      dplyr::pull("sum_oracle_value") |>
      unique() |>
      all.equal(1)
  )

  # expected categories are:
  # - NA near beginning, where there is not enough history to calculate rate change
  # - generally, a pattern of "large_increase" -> "increase" -> "stable" -> "decrease" -> "large_decrease".
  #   The exact pattern depends on the horizon/lookback window used for rate change.
  #   I figured out the right pattern by staring at the test_data.
  exp_categories <- data.frame(
    target_end_date = obs_dates,
    location = "US",
    horizon_0 = c(
                  rep(NA, 1),
                  rep("large_increase", 4),
                  rep("stable", 3),
                  rep("large_decrease", 4)),
    horizon_1 = c(
                  rep(NA, 2),
                  rep("large_increase", 3),
                  rep("increase", 1),
                  rep("stable", 2),
                  rep("decrease", 1),
                  rep("large_decrease", 3)),
    horizon_2 = c(
                  rep(NA, 3),
                  rep("large_increase", 2),
                  rep("increase", 2),
                  rep("stable", 1),
                  rep("decrease", 2),
                  rep("large_decrease", 2)),
    horizon_3 = c(rep(NA, 4),
                  rep("large_increase", 2),
                  rep("increase", 2),
                  rep("decrease", 2),
                  rep("large_decrease", 2))
  ) |>
    tidyr::pivot_longer(
      cols = c("horizon_0", "horizon_1", "horizon_2", "horizon_3"),
      names_to = "horizon",
      values_to = "output_type_id",
      names_prefix = "horizon_"
    ) |>
    dplyr::mutate(horizon = as.integer(.data$horizon)) |>
    dplyr::filter(!is.na(.data$output_type_id))

  ok <- append(ok,
    test_oracle_output_rate_change |>
      dplyr::filter(
        .data$oracle_value > 0
      ) |>
      dplyr::select(-"oracle_value") |>
      dplyr::full_join(exp_categories, by = c("target_end_date", "location", "horizon")) |>
      dplyr::mutate(comparison = (.data$output_type_id.x == .data$output_type_id.y)) |>
      dplyr::pull("comparison") |>
      unique() |>
      all.equal(TRUE)
  )
}

#' @description
#' `create_target_data` returns Hubverse formatted weekly target data generated
#' by the FluSight Forecast hub.
#'
#' @param as_of Optional "YYYY-MM-DD" string. If provided, read archived target data instead of the latest version.
#' @param include_after "YYYY-MM_DD" string. Base target data dated on or earlier will be excluded.
create_target_data <- function(as_of = NULL, include_after = "2024-11-01") {
  # Validate input params
  tryCatch(
    as.Date(include_after, format = "%Y-%m-%d"),
    error = function(e) stop(paste0("Invalid date format for include_after. Please use 'YYYY-MM-DD': ", include_after))
  )
  if (!is.null(as_of)) {
    tryCatch(
      as.Date(as_of, format = "%Y-%m-%d"),
      error = function(e) stop(paste0("Invalid date format. Please use 'YYYY-MM-DD': ", as_of))
    )
  }

  # Get original target data from FluSight hub and filter using include_after
  location_data <- get_location_data()
  weekly_data_all <- get_base_target_data(as_of = as_of)
  weekly_data_all <- weekly_data_all %>%
    dplyr::filter(date > include_after)

  # create and write time series target data
  time_series_target <- create_time_series_target_data(weekly_data_all, location_data)
  as_of <- time_series_target$as_of[1]

  time_series_path <- file.path(here::here(), paste0("target-data/time-series/as_of=", as_of))
  time_series_filename <- "time-series.csv"
  if (!dir.exists(time_series_path)) {
    dir.create(time_series_path, recursive = TRUE)
  }
  tryCatch(
    write.csv(time_series_target, file = paste0(time_series_path, "/", time_series_filename), row.names = FALSE),
    error = function(e) {
      cli::cli_alert_danger(paste0(
                                  "Failed when writing time series target data to ",
                                  time_series_path,
                                  "/", time_series_filename, ":",
                                  e$message))
      quit(save = "no", status = 1)
    }
  )
  cli::cli_alert_success(paste0("Time series target data written to ", time_series_path, "/", time_series_filename))

  # create and write oracle output target data
  oracle_output_target <- create_oracle_output_target_data(time_series_target)

  oracle_output_path <- file.path(here::here(), paste0("target-data/oracle-output/as_of=", as_of))
  oracle_output_filename <- "oracle-output.csv"
  if (!dir.exists(oracle_output_path)) {
    dir.create(oracle_output_path, recursive = TRUE)
  }
  tryCatch(
    write.csv(oracle_output_target, file = paste0(oracle_output_path, "/", oracle_output_filename), row.names = FALSE),
    error = function(e) {
      cli::cli_alert_danger(paste0(
                                  "Failed when writing oracle output target data to ",
                                  oracle_output_path,
                                  "/", oracle_output_filename, ":",
                                  e$message))
      quit(save = "no", status = 1)
    }
  )
  cli::cli_alert_success(
    paste0("Oracle output target data written to ", oracle_output_path, "/", oracle_output_filename))

}

args <- commandArgs(trailingOnly = TRUE)
as_of <- args[1]
include_after <- args[2]

# if include_after date is not provided, default to the beginning
# of the 2024-2025 flu season
if (is.na(include_after) || is.null(include_after)) {
  include_after <- "2024-11-01"
}

# Run tests
ok <- run_target_data_tests()
ok <- ifelse(is.logical(ok), ok, FALSE)
if (isTRUE(all(ok))) {
  cli::cli_alert_success("All oracle rate change tests passed.")
} else {
  cli::cli_alert_danger("Oracle rate change tests failed: exiting script.")
  quit(save = "no", status = 1)
}

create_target_data(as_of = as_of, include_after = include_after)
